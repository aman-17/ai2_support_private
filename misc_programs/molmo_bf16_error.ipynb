{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amanr/.conda/envs/molmo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 83/83 [01:27<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/Molmo-72B-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Molmo-72B-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "inputs = processor.process(\n",
    "    images=[Image.open(requests.get(\"https://picsum.photos/id/237/536/354\", stream=True).raw)],\n",
    "    text=\"Describe this image.\"\n",
    ")\n",
    "inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "inputs[\"images\"] = inputs[\"images\"].to(torch.bfloat16)\n",
    "\n",
    "output = model.generate_from_batch(\n",
    "    inputs,\n",
    "    GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          ...,\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802]],\n",
      "\n",
      "         [[-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          ...,\n",
      "          [-1.5078, -1.5123, -1.2388,  ..., -0.5467, -0.5316, -0.3096],\n",
      "          [-1.6393, -1.6849, -1.4165,  ...,  0.0982,  0.1313,  0.2617],\n",
      "          [-0.7775, -0.8328, -0.5700,  ..., -1.4359, -1.3858, -1.1331]],\n",
      "\n",
      "         [[-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          ...,\n",
      "          [-0.3283, -0.5624, -0.6481,  ..., -0.6367, -0.8043, -0.8090],\n",
      "          [-0.4075, -0.6464, -0.7201,  ..., -0.4831, -0.6463, -0.6281],\n",
      "          [-0.2096, -0.4290, -0.4578,  ..., -1.2654, -1.3755, -1.1803]],\n",
      "\n",
      "         [[-1.1315, -1.2829, -1.0783,  ...,  0.0591, -0.1940, -0.2314],\n",
      "          [-0.6618, -0.8658, -0.8218,  ..., -0.2013, -0.4467, -0.5846],\n",
      "          [-0.2934, -0.4963, -0.5321,  ...,  0.1436, -0.1371, -0.2629],\n",
      "          ...,\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802]],\n",
      "\n",
      "         [[-1.0003, -0.9529, -0.6519,  ..., -1.4934, -1.4449, -1.1607],\n",
      "          [-1.0365, -0.9901, -0.6871,  ..., -1.7223, -1.6802, -1.4121],\n",
      "          [-1.6525, -1.6234, -1.2872,  ..., -1.1855, -1.1433, -0.8235],\n",
      "          ...,\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802],\n",
      "          [-1.7923, -1.7521, -1.4802,  ..., -1.7923, -1.7521, -1.4802]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs = processor.process(\n",
    "    images=[Image.open(requests.get(\"https://picsum.photos/id/237/536/354\", stream=True).raw)],\n",
    "    text=\"Describe this image.\"\n",
    ")\n",
    "inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "inputs[\"images\"] = inputs[\"images\"].to(torch.bfloat16)\n",
    "\n",
    "output = model.generate_from_batch(\n",
    "    inputs,\n",
    "    GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
